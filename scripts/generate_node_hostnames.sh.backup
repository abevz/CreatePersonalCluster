#!/bin/bash

# Generate cloud-init snippets with correct hostname for each node
# Enhanced with error handling and recovery mechanisms
# This script is meant to be run before applying the Terraform configuration

# Error handling constants
readonly ERROR_CONFIG=1
readonly ERROR_EXECUTION=2
readonly ERROR_INPUT=3
readonly SEVERITY_LOW=1
readonly SEVERITY_MEDIUM=2
readonly SEVERITY_HIGH=3
readonly SEVERITY_CRITICAL=4

# Logging functions
log_info() {
  echo "[INFO] $1"
}

log_error() {
  echo "[ERROR] $1" >&2
}

log_warning() {
  echo "[WARNING] $1"
}

log_success() {
  echo "[SUCCESS] $1"
}

# Error handling function
error_handle() {
    error_code="$1"
    error_message="$2"
    severity="$3"
    action="$4"

  log_error "$error_message (Error code: $error_code)"

  case "$action" in
    "abort")
      log_error "Aborting operation due to critical error"
      exit $error_code
      ;;
    "retry")
      log_warning "Will retry operation"
      ;;
    "continue")
      log_warning "Continuing despite error"
      ;;
    *)
      log_warning "Unknown error action: $action"
      ;;
  esac
}

# Recovery checkpoint function
recovery_checkpoint() {
    checkpoint_name="$1"
    description="$2"
  log_info "Recovery checkpoint: $checkpoint_name - $description"
}

# Validation functions
validate_dependencies() {
    missing_deps=()

  if ! command -v tofu &> /dev/null; then
    missing_deps+=("tofu")
  fi

  if ! command -v jq &> /dev/null; then
    missing_deps+=("jq")
  fi

  if ! command -v ssh &> /dev/null; then
    missing_deps+=("ssh")
  fi

  if ! command -v rsync &> /dev/null; then
    missing_deps+=("rsync")
  fi

  if [ ${#missing_deps[@]} -gt 0 ]; then
    error_handle "$ERROR_CONFIG" "Missing required dependencies: ${missing_deps[*]}" "$SEVERITY_CRITICAL" "abort"
    return 1
  fi

  return 0
}

validate_directory() {
    dir_path="$1"
    dir_name="$2"

  if [[ ! -d "$dir_path" ]]; then
    error_handle "$ERROR_CONFIG" "Directory not found: $dir_name ($dir_path)" "$SEVERITY_HIGH" "abort"
    return 1
  fi

  return 0
}

validate_file() {
    file_path="$1"
    file_name="$2"

  if [[ ! -f "$file_path" ]]; then
    error_handle "$ERROR_CONFIG" "File not found: $file_name ($file_path)" "$SEVERITY_HIGH" "abort"
    return 1
  fi

  return 0
}

# Initialize recovery for hostname generation
recovery_checkpoint "generate_hostnames_start" "Starting hostname generation process"

# Validate dependencies
if ! validate_dependencies; then
  exit 1
fi

# Check for necessary environment variables (SOPS secrets should be loaded by cpc)
if [ -z "$PROXMOX_HOST" ] || [ -z "$PROXMOX_USERNAME" ]; then
  error_handle "$ERROR_CONFIG" "Required environment variables not set. This script should be called via 'cpc' command." "$SEVERITY_CRITICAL" "abort"
  echo "Please run: cpc ctx <workspace> && cpc generate-hostnames"
  exit 1
fi

# Validate REPO_PATH
if [[ -z "$REPO_PATH" ]]; then
  error_handle "$ERROR_CONFIG" "REPO_PATH environment variable not set" "$SEVERITY_CRITICAL" "abort"
  exit 1
fi

if ! validate_directory "$REPO_PATH" "Repository path"; then
  exit 1
fi

# Load additional configuration variables from cpc.env
if [ -f "$REPO_PATH/cpc.env" ]; then
  if ! source "$REPO_PATH/cpc.env"; then
    error_handle "$ERROR_CONFIG" "Failed to source cpc.env configuration file" "$SEVERITY_HIGH" "abort"
    exit 1
  fi
else
  log_warning "cpc.env not found. Using default storage paths."
  PROXMOX_STORAGE_BASE_PATH="/DataPool"
  PROXMOX_DISK_DATASTORE="MyStorage"
fi

echo "Successfully loaded secrets (PROXMOX_HOST: $PROXMOX_HOST, PROXMOX_USERNAME: $PROXMOX_USERNAME)"
echo "Using storage configuration: ${PROXMOX_STORAGE_BASE_PATH}/${PROXMOX_DISK_DATASTORE}/snippets"

# Get the current workspace to determine release letter
if ! validate_directory "$REPO_PATH/terraform" "Terraform directory"; then
  exit 1
fi

if ! pushd "$REPO_PATH/terraform" >/dev/null; then
  error_handle "$ERROR_EXECUTION" "Failed to change to terraform directory" "$SEVERITY_HIGH" "abort"
  exit 1
fi

current_workspace=$(tofu workspace show 2>/dev/null)
if [ $? -ne 0 ]; then
  error_handle "$ERROR_EXECUTION" "Failed to get current tofu workspace" "$SEVERITY_HIGH" "abort"
  exit 1
fi

if ! popd >/dev/null; then
  error_handle "$ERROR_EXECUTION" "Failed to return to scripts directory" "$SEVERITY_HIGH" "abort"
  exit 1
fi

# Check if RELEASE_LETTER is already set in environment
if [ -z "$RELEASE_LETTER" ]; then
  # Try to load from workspace's .env file if it exists
  ENV_FILE="$REPO_PATH/envs/$current_workspace.env"
  if [ -f "$ENV_FILE" ]; then
    # Try to extract RELEASE_LETTER from the workspace's .env file
      env_release_letter
    if !   $(grep -E "^RELEASE_LETTER=" "$ENV_FILE" 2>/dev/null | cut -d'=' -f2 | tr -d '"' 2>/dev/null); then
      log_warning "Failed to extract RELEASE_LETTER from workspace .env file"
    elif [ -n "$env_release_letter" ]; then
      RELEASE_LETTER="$env_release_letter"
      echo "Using RELEASE_LETTER='$RELEASE_LETTER' from workspace .env file"
    fi
  fi

  # If still not found, fall back to the old mapping
  if [ -z "$RELEASE_LETTER" ]; then
    log_warning "RELEASE_LETTER not found in environment or workspace .env, falling back to mapping"
    # Map workspace to release letter (same logic as in locals.tf)
    case "$current_workspace" in
    "debian") RELEASE_LETTER="d" ;;
    "ubuntu") RELEASE_LETTER="u" ;;
    "rocky") RELEASE_LETTER="r" ;;
    "suse") RELEASE_LETTER="s" ;;
    *) RELEASE_LETTER="${current_workspace:0:1}" ;; # fallback to first letter of workspace
    esac
    echo "Mapped workspace '$current_workspace' to RELEASE_LETTER='$RELEASE_LETTER'"
  fi
fi

# Get cluster domain from Terraform variables
  vm_domain
if ! validate_file "$REPO_PATH/terraform/variables.tf" "Terraform variables file"; then
  exit 1
fi

if ! vm_domain=$(grep -E "^VM_DOMAIN=" "$ENV_FILE" 2>/dev/null | cut -d'=' -f2 | tr -d '"' 2>/dev/null); then
  error_handle "$ERROR_EXECUTION" "Failed to extract VM domain from terraform variables" "$SEVERITY_MEDIUM" "continue"
  vm_domain="local"  # fallback
fi

# Get node information from the terraform output
echo "Getting node information from terraform output..."

if ! pushd "$REPO_PATH/terraform" >/dev/null; then
  error_handle "$ERROR_EXECUTION" "Failed to change to terraform directory for node info retrieval" "$SEVERITY_HIGH" "abort"
  exit 1
fi

  node_info
if ! node_info=$(tofu output -json node_info 2>/dev/null); then
  error_handle "$ERROR_EXECUTION" "Failed to get node information from tofu output" "$SEVERITY_MEDIUM" "continue"
  node_info=""
fi

if ! popd >/dev/null; then
  error_handle "$ERROR_EXECUTION" "Failed to return to scripts directory after node info retrieval" "$SEVERITY_HIGH" "abort"
  exit 1
fi

# Initialize arrays
HOSTNAMES=()
ROLES=()
INDICES=()

# If the tofu output command succeeds and is not empty, parse the JSON
if [ -n "$node_info" ] && [ "$node_info" != "null" ]; then
  echo "Successfully got node information from tofu output."
  while read -r key hostname; do
    if [[ -z "$hostname" ]]; then
      continue
    fi

      short_hostname
    if ! short_hostname=$(echo "$hostname" | cut -d'.' -f1 2>/dev/null); then
      error_handle "$ERROR_EXECUTION" "Failed to extract short hostname from: $hostname" "$SEVERITY_LOW" "continue"
      continue
    fi

      role="${short_hostname:0:1}"
      index="${short_hostname:2}"

    HOSTNAMES+=("$hostname")
    ROLES+=("$role")
    INDICES+=("$index")
  done < <(echo "$node_info" | jq -r 'to_entries[] | "\(.key) \(.value)"' 2>/dev/null)
else
  log_warning "Could not get node information from terraform output. Falling back to default node definitions."
  # Fallback logic for new workspaces
  HOSTNAMES=() # Ensure it's empty
  ROLES=("c" "w" "w")
  INDICES=("1" "2" "3") # Note: Terraform logic uses original_index 1, 1, 2. Let's stick to simple logic here for fallback.
fi

# Create snippets directory if it doesn't exist
snippets_dir="$REPO_PATH/terraform/snippets"
echo "Debug: snippets_dir='$snippets_dir'"
# shellcheck disable=SC2164
if ! mkdir -p "$snippets_dir"; then
  error_handle "$ERROR_EXECUTION" "Failed to create snippets directory: $snippets_dir" "$SEVERITY_HIGH" "abort"
  exit 1
fi

echo "Generating cloud-init snippets for each node..."

# For each node, generate a cloud-init snippet with the correct hostname
for i in "${!ROLES[@]}"; do
    role="${ROLES[$i]}"
    index

  # Adjust index for workers in fallback mode
  if [ ${#HOSTNAMES[@]} -eq 0 ]; then
    if [ "$role" == "w" ]; then
      index=$((i))
    else
      index=1
    fi
  else
    index="${INDICES[$i]}"
  fi

  # If we have full hostnames from terraform output, use them
    fqdn
  if [ ${#HOSTNAMES[@]} -gt 0 ] && [ -n "${HOSTNAMES[$i]}" ]; then
    fqdn="${HOSTNAMES[$i]}"
  else
    # Fall back to generating the hostname from components
      clean_domain=${vm_domain#.}
      hostname="${role}${RELEASE_LETTER}${index}"
    fqdn="${hostname}.${clean_domain}"
  fi

  echo "Generated hostname: $fqdn"

  # Validate hostname template exists
    template_file="$REPO_PATH/terraform/snippets/hostname-template.yaml"
  if ! validate_file "$template_file" "Hostname template file"; then
    exit 1
  fi

  # Create a cloud-init snippet for this node
    node_key="node-${role}${RELEASE_LETTER}${index}-userdata.yaml"
    output_file="$snippets_dir/$node_key"

  if ! cat "$template_file" | sed "s|\${hostname}|$fqdn|g" >"$output_file" 2>/dev/null; then
    error_handle "$ERROR_EXECUTION" "Failed to create cloud-init snippet for $fqdn" "$SEVERITY_HIGH" "abort"
    exit 1
  fi

  echo "Created cloud-init snippet for $fqdn"
done

echo "Done. Created $(ls -la $snippets_dir/node-*-userdata.yaml 2>/dev/null | wc -l) cloud-init snippets."

# Create a summary file for Terraform to use
echo "Creating summary file for Terraform..."
  summary_file="$snippets_dir/summary.txt"

if ! echo "# Auto-generated cloud-init snippets" >"$summary_file" 2>/dev/null; then
  error_handle "$ERROR_EXECUTION" "Failed to create summary file: $summary_file" "$SEVERITY_MEDIUM" "continue"
else
  echo "# Generated on $(date)" >>"$summary_file"
  echo "# Node count: ${#ROLES[@]}" >>"$summary_file"
fi

# Copy snippets to Proxmox host
echo "Debug: PROXMOX_HOST='$PROXMOX_HOST', PROXMOX_USERNAME='$PROXMOX_USERNAME'"
if [ -n "$PROXMOX_HOST" ] && [ -n "$PROXMOX_USERNAME" ]; then
  echo "Copying snippets to Proxmox host..."

    snippets_path="${PROXMOX_STORAGE_BASE_PATH}/${PROXMOX_DISK_DATASTORE}/snippets"

  # Test SSH connection first
  if ! ssh -o ConnectTimeout=5 -o StrictHostKeyChecking=no "$PROXMOX_USERNAME@$PROXMOX_HOST" "echo 'SSH connection successful'" >/dev/null 2>&1; then
    error_handle "$ERROR_EXECUTION" "SSH connection to Proxmox host failed" "$SEVERITY_HIGH" "abort"
    exit 1
  fi

  # Ensure the remote directory exists
  if ! ssh "$PROXMOX_USERNAME@$PROXMOX_HOST" "sudo mkdir -p $snippets_path" 2>/dev/null; then
    error_handle "$ERROR_EXECUTION" "Failed to create remote snippets directory: $snippets_path" "$SEVERITY_HIGH" "abort"
    exit 1
  fi

  # Use rsync for efficient copying with retry
    max_retries=3
    retry_count=0
    rsync_success=false

  while [ $retry_count -le $max_retries ]; do
    if [ $retry_count -gt 0 ]; then
      log_info "Retrying rsync copy (attempt $((retry_count + 1))/$((max_retries + 1)))..."
      sleep 2
    fi

    if rsync -avz --progress "$snippets_dir/" "$PROXMOX_USERNAME@$PROXMOX_HOST:/tmp/cpc-snippets" >/dev/null 2>&1; then
      rsync_success=true
      break
    fi

    retry_count=$((retry_count + 1))

    if [ $retry_count -le $max_retries ]; then
      error_handle "$ERROR_EXECUTION" "rsync copy failed (attempt $retry_count), will retry" "$SEVERITY_MEDIUM" "retry"
    fi
  done

  if [ "$rsync_success" = false ]; then
    error_handle "$ERROR_EXECUTION" "Failed to copy snippets to Proxmox host after $((retry_count)) attempts" "$SEVERITY_CRITICAL" "abort"
    exit 1
  fi

  # Copy files to final location on remote host
  if ! ssh "$PROXMOX_USERNAME@$PROXMOX_HOST" "sudo cp /tmp/cpc-snippets/* $snippets_path/ && sudo chmod 644 $snippets_path/*" 2>/dev/null; then
    error_handle "$ERROR_EXECUTION" "Failed to copy snippets to final location on Proxmox host" "$SEVERITY_HIGH" "abort"
    exit 1
  fi

  echo "Done copying snippets to Proxmox host at $snippets_path/"
else
  log_warning "Proxmox host configuration not complete, skipping remote copy"
fi

log_success "Hostname generation process completed successfully"
